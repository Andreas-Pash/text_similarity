{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import ast\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords',quiet=True)\n",
    "# nltk.download('wordnet', quiet=True)\n",
    "# nltk.download('punkt',quiet=True)\n",
    "\n",
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pre_pre_processing(df:pd.DataFrame):\n",
    "    df= (df[[\"wonum\",\"description\",\"ldtext\",\"mats_assigned\",\"wopriority\",\"actstart\"]]\n",
    "         .drop_duplicates()\n",
    "         .reset_index(drop=True)\n",
    "    )\n",
    "    df[[\"ldtext\", \"description\"]] = df[[\"ldtext\", \"description\"]].astype(str)\n",
    "    df[\"actstart\"] = pd.to_datetime(df[\"actstart\"])\n",
    "\n",
    "    un_wonums=(df[[\"wonum\"]].drop_duplicates(keep=False))\n",
    "    df=un_wonums.merge(df,on='wonum').reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:    u can !write up to \"\"3^*(%) 20GB to th^e current directory (/kaggle/working/) that gets preserved as output when you create a version using Save & Run All \n",
      "Transformed text:    ['write', 'current', 'directory', 'kaggleworking', 'get', 'preserved', 'output', 'create', 'version', 'using', 'save', 'run']\n"
     ]
    }
   ],
   "source": [
    "def text_pre_processing(text):\n",
    "\n",
    "    # Remove numbers and punctuation\n",
    "    clean_text = \"\".join([i for i in text if i.isalpha() or i.isspace()])\n",
    "    # Remove exceess whitespace\n",
    "    clean_text = re.sub(r'\\s+', ' ', clean_text)\n",
    "    # Transform to lower case\n",
    "    clean_text = clean_text.lower()\n",
    "\n",
    "    tokens = nltk.word_tokenize(clean_text)\n",
    "    #Removestopwords and character-like words\n",
    "    clean_tokens = [w for w in tokens if (not w in stopwords.words(\"english\")) and (len(w) > 2)]\n",
    "\n",
    "    # Lemmatizatize the words(not stemming as we will use doc2vec later on which captures the meaning of words, therefore stemming is not applicable in this case)\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in clean_tokens]\n",
    "\n",
    "    return lemm_text\n",
    "\n",
    "data = pd.DataFrame({\"text\": ['u can !write up to \"\"3^*(%) 20GB to th^e current directory (/kaggle/working/) that gets preserved as output when you create a version using Save & Run All ']*int(10e1)})\n",
    "data['clean_text'] = data['text'].apply(lambda x: text_pre_processing(x))\n",
    "print(f'Original text:    {data[\"text\"][0]}')\n",
    "print(f'Transformed text:    {data[\"clean_text\"][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_text_cols(df: pd.DataFrame, col1:str , col2:str):\n",
    "    \n",
    "    try:\n",
    "        for index, row in df.iterrows():\n",
    "            lst1 = ast.literal_eval(row[col1])\n",
    "            lst2 = ast.literal_eval(row[col2])\n",
    "            for item in lst2:\n",
    "                lst1.append(item)\n",
    "            df.loc[index,f\"{col1}_{col2}\"] = str(lst1)\n",
    "    except:\n",
    "        for index, row in df.iterrows():\n",
    "            lst1 = row[col1]\n",
    "            lst2 = row[col2]\n",
    "            for item in lst2:\n",
    "                lst1.append(item)\n",
    "    \n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_relevant_mats(columns, df):\n",
    "\n",
    "    def a2v_extraction(text):\n",
    "\n",
    "        if text != 'nan':\n",
    "            # Remove exceess whitespace\n",
    "            clean_text = re.sub(r'\\s+', ' ', text)\n",
    "            pattern = r'[!\"#$%&\\'()*+,-./:;<=>?@[\\]^_`{|}~]'\n",
    "            # Replace matched punctuation with a space\n",
    "            clean_text = re.sub(pattern, ' ', clean_text)\n",
    "            tokens = nltk.word_tokenize(clean_text)\n",
    "\n",
    "            a2v_nums = [(w)\n",
    "                        for w in tokens if w.startswith('A2V') and len(w) > 5]\n",
    "        else:\n",
    "            return ''\n",
    "\n",
    "        return \",\".join(list(set(a2v_nums)))\n",
    "\n",
    "    mats_cols = []\n",
    "    for col in columns:\n",
    "        df[f'mats_from_{col}'] = df[col].apply(a2v_extraction)\n",
    "        mats_cols.append(f'mats_from_{col}')\n",
    "\n",
    "    df['all_relevant_mats'] = (df[mats_cols].astype(str).apply(','.join, axis=1)\n",
    "                                            .apply(lambda x: list(set(x.split(','))))\n",
    "\n",
    "                               )\n",
    "\n",
    "    df = df.drop(columns=mats_cols)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sanitising(df: pd.DataFrame):\n",
    "\n",
    "    df[\"actstart\"] = pd.to_datetime(df[\"actstart\"])\n",
    "    df[\"clean_ldtext_size\"] = df[\"clean_ldtext\"].apply(lambda x: len(x))\n",
    "    df[\"clean_description_size\"] = df[\"clean_description\"].apply(lambda x: len(x))\n",
    "\n",
    "    # Fix data quality\n",
    "    df['clean_description'] = df['clean_description'].fillna('[]')\n",
    "    df['clean_ldtext'] = df['clean_ldtext'].fillna('[]')\n",
    "    df['ldtext'] = df['ldtext'].astype(str)\n",
    "    df['description'] = df['description'].astype(str)\n",
    "    df['clean_ldtext'] = df['clean_ldtext'].astype(str)\n",
    "    df['clean_description'] = df['clean_description'].astype(str)\n",
    "    \n",
    "    df = df.replace({\"['nan']\": '[]', '[nan]': '[]'})\n",
    "    df = df.drop(df[df[\"ldtext\"].astype(str).apply(lambda x: x.startswith('[if gte mso 9]&'))].index,axis=0).reset_index(drop=True)\n",
    "\n",
    "    #Merge clean_description and clean_ldtext\n",
    "    df = merge_text_cols(df,\"clean_description\",\"clean_ldtext\")\n",
    "    cols = ['description', 'ldtext']\n",
    "    df = gather_relevant_mats(cols, df) \n",
    "        \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_matches(df):\n",
    "    \n",
    "    df1 = df.groupby([\"clean_description\", \"clean_ldtext\"], dropna = False).count()\n",
    "    df1 = (df1[df1[\"wonum\"] > 1][\"wonum\"].reset_index(drop=False))\n",
    "    df1 = df1.rename(columns={\"wonum\": \"count\"}).reset_index(drop=True)\n",
    "    df1[\"group_id\"] = df1.index \n",
    "    df = df.merge(df1,on= [\"clean_description\", \"clean_ldtext\"], how='left')\n",
    "    \n",
    "    group_map = (df.groupby(\"group_id\", dropna=True)['wonum'].apply(lambda x: \",\".join(x))\n",
    "                 .reset_index()\n",
    "                 .rename(columns={\"wonum\": \"similar_clean_description_ldtext\"})\n",
    "                )\n",
    "    df = df.merge(group_map, on=[\"group_id\"], how='left')\n",
    "    \n",
    "    df[\"exact_match\"] = np.where(df[\"group_id\"].isna(),0,1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6677 entries, 0 to 6676\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   wonum                 6677 non-null   object \n",
      " 1   imo_act_causing_part  4396 non-null   object \n",
      " 2   description           6677 non-null   object \n",
      " 3   workorderid           6677 non-null   int64  \n",
      " 4   wopriority            5129 non-null   float64\n",
      " 5   worktype              6677 non-null   object \n",
      " 6   actstart              6376 non-null   object \n",
      " 7   assetnum              5536 non-null   object \n",
      " 8   location              5706 non-null   object \n",
      " 9   siteid                6677 non-null   object \n",
      " 10  wonum.1               381 non-null    object \n",
      " 11  mats_assigned         381 non-null    object \n",
      " 12  ldkey                 4123 non-null   float64\n",
      " 13  ldtext                4109 non-null   object \n",
      "dtypes: float64(2), int64(1), object(11)\n",
      "memory usage: 730.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"brake_workorders.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wonum</th>\n",
       "      <th>description</th>\n",
       "      <th>ldtext</th>\n",
       "      <th>mats_assigned</th>\n",
       "      <th>wopriority</th>\n",
       "      <th>actstart</th>\n",
       "      <th>clean_ldtext</th>\n",
       "      <th>clean_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1372443</td>\n",
       "      <td>Re-Instate Brake Smart Valve</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-10-20 19:11:57</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[reinstate, brake, smart, valve]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TLW1660664</td>\n",
       "      <td>20/03 411 Brake Release Key Missing</td>\n",
       "      <td>401 cab lower cup holder damaged - ATTENDED no...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020-03-21 12:35:02</td>\n",
       "      <td>[cab, lower, cup, holder, damaged, attended, n...</td>\n",
       "      <td>[brake, release, key, missing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TLW2429000</td>\n",
       "      <td>Re-Instate Brake Smart Valve</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2024-01-11 15:10:43</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[reinstate, brake, smart, valve]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1139804</td>\n",
       "      <td>Intercar Gangway Disconnected</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2017-08-01 12:48:49</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[intercar, gangway, disconnected]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TLW1927638</td>\n",
       "      <td>411 - EP2002 Smart Valve Failing brake test to...</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2021-10-10 16:00:00</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[smart, valve, failing, brake, test, replaced,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        wonum                                        description  \\\n",
       "0     1372443                       Re-Instate Brake Smart Valve   \n",
       "1  TLW1660664                20/03 411 Brake Release Key Missing   \n",
       "2  TLW2429000                       Re-Instate Brake Smart Valve   \n",
       "3     1139804                      Intercar Gangway Disconnected   \n",
       "4  TLW1927638  411 - EP2002 Smart Valve Failing brake test to...   \n",
       "\n",
       "                                              ldtext mats_assigned  \\\n",
       "0                                                nan           NaN   \n",
       "1  401 cab lower cup holder damaged - ATTENDED no...           NaN   \n",
       "2                                                nan           NaN   \n",
       "3                                                nan           NaN   \n",
       "4                                                nan           NaN   \n",
       "\n",
       "   wopriority            actstart  \\\n",
       "0         NaN 2018-10-20 19:11:57   \n",
       "1         5.0 2020-03-21 12:35:02   \n",
       "2         9.0 2024-01-11 15:10:43   \n",
       "3         9.0 2017-08-01 12:48:49   \n",
       "4         9.0 2021-10-10 16:00:00   \n",
       "\n",
       "                                        clean_ldtext  \\\n",
       "0                                              [nan]   \n",
       "1  [cab, lower, cup, holder, damaged, attended, n...   \n",
       "2                                              [nan]   \n",
       "3                                              [nan]   \n",
       "4                                              [nan]   \n",
       "\n",
       "                                   clean_description  \n",
       "0                   [reinstate, brake, smart, valve]  \n",
       "1                     [brake, release, key, missing]  \n",
       "2                   [reinstate, brake, smart, valve]  \n",
       "3                  [intercar, gangway, disconnected]  \n",
       "4  [smart, valve, failing, brake, test, replaced,...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=data_pre_pre_processing(df)\n",
    "df[\"clean_ldtext\"] = df['ldtext'].apply(lambda x: text_pre_processing(x))\n",
    "df[\"clean_description\"] = df['description'].apply(lambda x: text_pre_processing(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wonum</th>\n",
       "      <th>description</th>\n",
       "      <th>ldtext</th>\n",
       "      <th>mats_assigned</th>\n",
       "      <th>wopriority</th>\n",
       "      <th>actstart</th>\n",
       "      <th>clean_ldtext</th>\n",
       "      <th>clean_description</th>\n",
       "      <th>clean_ldtext_size</th>\n",
       "      <th>clean_description_size</th>\n",
       "      <th>clean_description_clean_ldtext</th>\n",
       "      <th>all_relevant_mats</th>\n",
       "      <th>count</th>\n",
       "      <th>group_id</th>\n",
       "      <th>similar_clean_description_ldtext</th>\n",
       "      <th>exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1372443</td>\n",
       "      <td>Re-Instate Brake Smart Valve</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-10-20 19:11:57</td>\n",
       "      <td>[]</td>\n",
       "      <td>['reinstate', 'brake', 'smart', 'valve']</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>['reinstate', 'brake', 'smart', 'valve']</td>\n",
       "      <td>[]</td>\n",
       "      <td>1380.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1372443,TLW2429000,TLW2179413,TLW1824466,TLW24...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TLW1660664</td>\n",
       "      <td>20/03 411 Brake Release Key Missing</td>\n",
       "      <td>401 cab lower cup holder damaged - ATTENDED no...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2020-03-21 12:35:02</td>\n",
       "      <td>['cab', 'lower', 'cup', 'holder', 'damaged', '...</td>\n",
       "      <td>['brake', 'release', 'key', 'missing']</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>['brake', 'release', 'key', 'missing', 'cab', ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TLW2429000</td>\n",
       "      <td>Re-Instate Brake Smart Valve</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2024-01-11 15:10:43</td>\n",
       "      <td>[]</td>\n",
       "      <td>['reinstate', 'brake', 'smart', 'valve']</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>['reinstate', 'brake', 'smart', 'valve']</td>\n",
       "      <td>[]</td>\n",
       "      <td>1380.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1372443,TLW2429000,TLW2179413,TLW1824466,TLW24...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        wonum                          description  \\\n",
       "0     1372443         Re-Instate Brake Smart Valve   \n",
       "1  TLW1660664  20/03 411 Brake Release Key Missing   \n",
       "2  TLW2429000         Re-Instate Brake Smart Valve   \n",
       "\n",
       "                                              ldtext mats_assigned  \\\n",
       "0                                                nan           NaN   \n",
       "1  401 cab lower cup holder damaged - ATTENDED no...           NaN   \n",
       "2                                                nan           NaN   \n",
       "\n",
       "   wopriority            actstart  \\\n",
       "0         NaN 2018-10-20 19:11:57   \n",
       "1         5.0 2020-03-21 12:35:02   \n",
       "2         9.0 2024-01-11 15:10:43   \n",
       "\n",
       "                                        clean_ldtext  \\\n",
       "0                                                 []   \n",
       "1  ['cab', 'lower', 'cup', 'holder', 'damaged', '...   \n",
       "2                                                 []   \n",
       "\n",
       "                          clean_description  clean_ldtext_size  \\\n",
       "0  ['reinstate', 'brake', 'smart', 'valve']                  1   \n",
       "1    ['brake', 'release', 'key', 'missing']                 10   \n",
       "2  ['reinstate', 'brake', 'smart', 'valve']                  1   \n",
       "\n",
       "   clean_description_size                     clean_description_clean_ldtext  \\\n",
       "0                       4           ['reinstate', 'brake', 'smart', 'valve']   \n",
       "1                       4  ['brake', 'release', 'key', 'missing', 'cab', ...   \n",
       "2                       4           ['reinstate', 'brake', 'smart', 'valve']   \n",
       "\n",
       "  all_relevant_mats   count  group_id  \\\n",
       "0                []  1380.0     172.0   \n",
       "1                []     NaN       NaN   \n",
       "2                []  1380.0     172.0   \n",
       "\n",
       "                    similar_clean_description_ldtext  exact_match  \n",
       "0  1372443,TLW2429000,TLW2179413,TLW1824466,TLW24...            1  \n",
       "1                                                NaN            0  \n",
       "2  1372443,TLW2429000,TLW2179413,TLW1824466,TLW24...            1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data_sanitising(df)\n",
    "df = exact_matches(df)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 =df.copy()\n",
    "df0['clean_description'] = df0['clean_description'].apply(lambda w: \" \".join( ast.literal_eval(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3278 entries, 1 to 5629\n",
      "Data columns (total 17 columns):\n",
      " #   Column                            Non-Null Count  Dtype         \n",
      "---  ------                            --------------  -----         \n",
      " 0   wonum                             3278 non-null   object        \n",
      " 1   description                       3278 non-null   object        \n",
      " 2   ldtext                            3278 non-null   object        \n",
      " 3   mats_assigned                     279 non-null    object        \n",
      " 4   wopriority                        3148 non-null   float64       \n",
      " 5   actstart                          3086 non-null   datetime64[ns]\n",
      " 6   clean_ldtext                      3278 non-null   object        \n",
      " 7   clean_description                 3278 non-null   object        \n",
      " 8   clean_ldtext_size                 3278 non-null   int64         \n",
      " 9   clean_description_size            3278 non-null   int64         \n",
      " 10  clean_description_clean_ldtext    3278 non-null   object        \n",
      " 11  all_relevant_mats                 3278 non-null   object        \n",
      " 12  count                             0 non-null      float64       \n",
      " 13  group_id                          0 non-null      float64       \n",
      " 14  similar_clean_description_ldtext  0 non-null      object        \n",
      " 15  exact_match                       3278 non-null   int32         \n",
      " 16  wonum_fuzz_matches                3278 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(3), int32(1), int64(2), object(10)\n",
      "memory usage: 448.2+ KB\n"
     ]
    }
   ],
   "source": [
    "non_exact_ld_matches_df = df[(df[\"exact_match\"] == 0)].reset_index(drop= True)\n",
    "test_df = non_exact_ld_matches_df.copy()\n",
    "\n",
    "non_exact_ld_matches_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf_similarity_df(df:pd.DataFrame, col: str, vect_max_feats : int =500 ,n_splits: int = 10):\n",
    "      \n",
    "      if n_splits <= 0 or n_splits > len(df):\n",
    "        raise ValueError(\n",
    "            \"n_splits should be a positive integer less than or equal to the length of the dataframe\")\n",
    "\n",
    "      q_sim_df = pd.DataFrame()\n",
    "\n",
    "      corpus = [\" \".join( (ast.literal_eval(text))) for text in df[col][0:int(len(df)/n_splits)]]\n",
    "      vectorizer = TfidfVectorizer(ngram_range=(1,1), max_features = vect_max_feats)\n",
    "      X = vectorizer.fit_transform(corpus).astype(np.float32)\n",
    "\n",
    "      print(f'We have {len(corpus)} documents and {len(set(vectorizer.get_feature_names_out()))} unique words in our corpus.\\n'\n",
    "            f'Tf-idf matrix is a {X,X.dtype}') \n",
    "\n",
    "      \n",
    "      sim_mat = cosine_similarity(X)#.astype(np.float32)\n",
    "      q_sim_df = pd.DataFrame.sparse.from_spmatrix(csr_matrix(np.round(sim_mat.data, 2)))\n",
    "      \n",
    "      return q_sim_df\n",
    "\n",
    "\n",
    "def get_cluster_info(des_mat: pd.DataFrame, df: pd.DataFrame, key_word: str, similarity: float):\n",
    "    \n",
    "      words = key_word.split(\" \")\n",
    "      # \" \".join(text_pre_processing(key_word))\n",
    "      matches = df[df[\"clean_description\"].apply(lambda x: all(word in ast.literal_eval(x) for word in words))]\n",
    "\n",
    "      if len(matches) != 0:\n",
    "            print(f'Which description best matches what you are looking for?\\n')\n",
    "            print(matches['description'].head(50))\n",
    "      else:\n",
    "            print('No matches found in this dataset')\n",
    "      \n",
    "      key = input()\n",
    "\n",
    "      return df.iloc[des_mat[des_mat[int(key)] > similarity].sort_values( int(key), ascending=False).index]\n",
    "\n",
    "\n",
    "def get_similar_wonums(des_mat: pd.DataFrame, df: pd.DataFrame, index_key: int, similarity: float):\n",
    "\n",
    "      matches = df.iloc[des_mat[des_mat[int(index_key)] > similarity].sort_values(int(index_key), ascending=False).index]\n",
    "     \n",
    "      if (len(matches) != 0) and (len(matches) != 1):\n",
    "          print(f'Descriptions matched:\\n')\n",
    "          print(matches['description'].drop_duplicates().head(50))\n",
    "\n",
    "      else:\n",
    "          print('No matches found in this dataset')\n",
    "          return None\n",
    "\n",
    "      return \",\".join(matches['wonum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 5630 documents and 1000 unique words in our corpus.\n",
      "Tf-idf matrix is a (<5630x1000 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 27803 stored elements in Compressed Sparse Row format>, dtype('float32'))\n",
      "Descriptions matched:\n",
      "\n",
      "0       Re-Instate Brake Smart Valve\n",
      "3622    Re-Instate Brake Smart Valve\n",
      "3650    Re-Instate Brake Smart Valve\n",
      "3649    Re-Instate Brake Smart Valve\n",
      "3648    Re-Instate Brake Smart Valve\n",
      "3645    Re-Instate Brake Smart Valve\n",
      "3644    Re-Instate Brake Smart Valve\n",
      "3631    Re-Instate Brake Smart Valve\n",
      "3627    Re-Instate Brake Smart Valve\n",
      "3626    Re-Instate Brake Smart Valve\n",
      "3625    Re-Instate Brake Smart Valve\n",
      "3619    Re-Instate Brake Smart Valve\n",
      "3653    Re-Instate Brake Smart Valve\n",
      "3618    Re-Instate Brake Smart Valve\n",
      "3613    Re-Instate Brake Smart Valve\n",
      "3610    Re-Instate Brake Smart Valve\n",
      "3609    Re-Instate Brake Smart Valve\n",
      "3608    Re-Instate Brake Smart Valve\n",
      "3607    Re-Instate Brake Smart Valve\n",
      "3604    Re-Instate Brake Smart Valve\n",
      "3602    Re-Instate Brake Smart Valve\n",
      "3600    Re-Instate Brake Smart Valve\n",
      "3652    Re-Instate Brake Smart Valve\n",
      "3658    Re-Instate Brake Smart Valve\n",
      "4145    Re-Instate Brake Smart Valve\n",
      "3724    Re-Instate Brake Smart Valve\n",
      "3749    Re-Instate Brake Smart Valve\n",
      "3746    Re-Instate Brake Smart Valve\n",
      "3741    Re-Instate Brake Smart Valve\n",
      "3738    Re-Instate Brake Smart Valve\n",
      "3737    Re-Instate Brake Smart Valve\n",
      "3735    Re-Instate Brake Smart Valve\n",
      "3733    Re-Instate Brake Smart Valve\n",
      "3731    Re-Instate Brake Smart Valve\n",
      "3727    Re-Instate Brake Smart Valve\n",
      "3720    Re-Instate Brake Smart Valve\n",
      "3670    Re-Instate Brake Smart Valve\n",
      "3710    Re-Instate Brake Smart Valve\n",
      "3707    Re-Instate Brake Smart Valve\n",
      "3694    Re-Instate Brake Smart Valve\n",
      "3693    Re-Instate Brake Smart Valve\n",
      "3692    Re-Instate Brake Smart Valve\n",
      "3689    Re-Instate Brake Smart Valve\n",
      "3685    Re-Instate Brake Smart Valve\n",
      "3684    Re-Instate Brake Smart Valve\n",
      "3677    Re-Instate Brake Smart Valve\n",
      "3597    Re-Instate Brake Smart Valve\n",
      "3595    Re-Instate Brake Smart Valve\n",
      "3594    Re-Instate Brake Smart Valve\n",
      "3489    Re-Instate Brake Smart Valve\n",
      "Name: description, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1372443,TLW1752580,TLW2018324,TLW2571872,TLW1618016,TLW2106313,TLW1719290,TLW2009400,TLW2626138,1448024,TLW1887486,TLW2092104,TLW1734981,1511249,TLW2412155,TLW2003339,TLW2632139,TLW1778755,TLW1520688,TLW2222383,TLW1632600,TLW2229808,TLW1676264,TLW2405347,1339216,TLW2239472,TLW2368265,TLW2145620,TLW1783025,TLW1645665,TLW2236372,TLW1791963,TLW1674462,TLW2531633,TLW1713426,TLW2406804,TLW1628611,TLW2312927,TLW2069984,TLW1804552,TLW1757125,1452042,TLW2285244,TLW2645010,TLW2155216,TLW2590817,TLW1679160,TLW2339111,TLW2328756,1458196,TLW2353186,TLW1745864,TLW2432063,TLW1916373,TLW1799103,TLW1537974,TLW2375176,TLW2313190,TLW2129271,TLW1791450,TLW2316285,TLW1565536,TLW1792946,TLW2251999,TLW1704235,TLW2534011,TLW1860877,TLW1850925,TLW2524110,TLW1960006,TLW2590749,TLW2008320,TLW2555131,TLW2559091,TLW1997923,TLW1646772,TLW1711487,TLW1853656,TLW2479031,1311491,TLW2453613,TLW2391764,TLW2263974,TLW2136047,TLW2375214,TLW1825350,TLW2403164,TLW2257879,TLW2420996,TLW1676715,TLW2320111,TLW1601671,TLW2095780,TLW2331438,TLW2272464,TLW2090329,TLW2286731,TLW2049583,TLW1722207,TLW1771288,TLW2174240,TLW1976545,TLW2100426,TLW2438729,TLW2458982,TLW1988682,TLW1817593,1445238,TLW1722304,TLW2025225,1417518,TLW2374157,TLW2172087,TLW1632426,TLW2119599,TLW2171997,TLW2412857,TLW1840149,TLW1695154,TLW2305283,1453990,TLW2049054,TLW2623672,TLW1518890,TLW2046487,TLW1645273,1387289,TLW1654841,TLW1839166,TLW1604747,TLW1622842,TLW1791768,TLW1976996,TLW2205572,TLW2193558,TLW1686473,TLW2508865,TLW1737186,TLW2189955,TLW1583271,TLW2333529,TLW2061903,TLW2648647,TLW1800693,TLW1595907,TLW2119848,TLW2306041,TLW2465407,TLW1810256,TLW2085576,TLW2141950,1487991,TLW2510352,TLW1975977,TLW1994715,TLW2032803,TLW1996040,TLW2123933,TLW2060748,TLW2093943,TLW2190999,TLW1582710,TLW1725189,TLW2250840,TLW1670254,TLW2015031,TLW1692987,TLW1634254,TLW2227734,TLW1713940,1306213,TLW1984319,TLW2555047,TLW1909994,TLW2440601,1441907,TLW2337389,TLW2099694,TLW2037927,TLW2438669,TLW2588397,TLW2414572,TLW1650519,TLW2305452,TLW1871190,TLW2130418,TLW2235305,TLW2460647,TLW1631417,TLW1772269,TLW2642492,TLW2018018,TLW2177675,TLW1522542,TLW2637465,TLW1803373,TLW2373594,1492190,TLW2617803,1359634,TLW2170620,TLW2214762,TLW2539353,TLW1694335,TLW1617518,TLW1672764,TLW1835345,TLW1809893,TLW1725218,TLW2310571,TLW2051477,TLW2028005,TLW1696590,TLW2205323,TLW2308263,TLW1699496,TLW2319308,1365082,TLW2547359,TLW2224602,TLW2444304,TLW2031873,TLW2265398,TLW2232566,TLW2055998,TLW2304190,TLW2371237,TLW2139408,TLW2344751,TLW1551033,TLW1816211,TLW1687299,TLW2483739,TLW2359945,TLW2488342,TLW2416094,TLW2315763,TLW1652317,TLW2120050,TLW2025663,TLW1977974,TLW1721883,TLW2105512,TLW2144680,TLW2116403,1510528,TLW2053274,TLW2012403,TLW2107395,TLW2070790,TLW1614960,TLW1962384,TLW2201868,TLW2487122,TLW1684774,TLW1764230,TLW1762590,TLW2029560,TLW1602570,TLW2442367,TLW1705832,TLW2165675,TLW1923175,TLW1675445,TLW2181843,TLW2550882,TLW1651185,TLW2019193,TLW1761079,TLW2125274,TLW1786101,TLW2058041,TLW2074783,TLW2219390,TLW2421970,1459719,TLW1607646,TLW2430336,TLW1763315,TLW1761587,TLW2390637,TLW2273030,TLW1700456,TLW2304438,TLW2515245,TLW2641321,1391698,TLW2362629,TLW2381983,TLW2397003,TLW1866633,TLW1953955,TLW2300429,TLW1782153,TLW2205993,TLW2192641,TLW2167051,TLW1878583,TLW2003965,TLW2232574,TLW1838109,TLW1674184,TLW1574116,TLW2473148,TLW2122831,TLW2388316,TLW1923079,TLW1826091,TLW2353558,TLW1543028,TLW1701956,TLW1818446,TLW1692744,TLW2008468,TLW1969845,TLW1768484,TLW2279801,TLW2351698,TLW2425809,TLW1517076,TLW2578972,TLW2120977,TLW2337322,TLW2444057,TLW2628577,TLW2551919,TLW2332343,TLW1719227,TLW2230064,TLW2237704,TLW2499992,TLW2311783,TLW2371834,TLW2233460,TLW1767700,TLW1838848,TLW1849336,TLW2180439,TLW2219911,TLW1867464,TLW2608798,TLW2302277,TLW2417598,1417160,TLW1684973,TLW1621825,TLW1966893,TLW2092720,TLW1847130,TLW2117380,TLW1972813,TLW1970913,1464299,TLW1650557,TLW2203680,TLW2625811,TLW2481727,TLW1962941,1500262,TLW2037797,TLW1653721,TLW2172571,1323333,1456672,TLW1812921,1421916,TLW2362319,TLW1848095,1412864,TLW1739281,TLW2262410,TLW2245430,TLW2439902,1487836,TLW2106331,TLW1960310,TLW2476420,TLW2382031,TLW2196456,TLW1591860,TLW1673325,TLW1977916,TLW1648568,TLW2204449,TLW1918134,TLW1983558,TLW1908536,1337469,1502894,1484502,TLW2166920,TLW2304863,TLW1839279,TLW2361091,TLW2151807,TLW2498265,TLW1731332,TLW2330846,TLW1952825,TLW1820955,TLW1845567,TLW1985476,TLW2190558,TLW2267085,TLW1906067,TLW2248946,TLW1517464,TLW2305748,TLW2405712,TLW2590764,1503166,TLW1554414,TLW2403526,TLW1627271,TLW2481407,TLW1540708,TLW2165187,TLW2424007,TLW1837321,TLW2372845,1404416,TLW1817064,TLW2275727,TLW2158507,TLW2012996,TLW2431272,TLW2274555,TLW2002737,TLW1564713,TLW1988851,TLW2052613,TLW2591269,TLW2012280,TLW2470945,TLW2463014,TLW1549644,TLW2648149,TLW2323456,TLW2343415,TLW1660450,TLW2190715,TLW2048039,TLW1718507,TLW1570112,TLW1586394,TLW2625512,TLW2274903,TLW2078715,TLW2404319,TLW1917957,TLW1548510,1431293,TLW1742151,TLW1550165,TLW1790690,TLW2240328,TLW1909150,TLW1733012,TLW1915309,TLW2477471,1396087,1374750,TLW2525944,TLW1711841,TLW2541568,TLW2053141,TLW1538527,TLW1872139,TLW2391848,TLW1658831,TLW2327639,TLW2643746,TLW2358734,TLW1914126,TLW1988984,TLW2335661,TLW2163211,TLW1969390,TLW2375150,TLW2506298,TLW2262041,TLW2091074,TLW1914980,TLW1908134,TLW2138338,TLW2363527,TLW1833361,TLW1883029,TLW2003011,TLW1821933,TLW2212037,TLW1677523,TLW2564402,TLW1811377,TLW1877470,TLW2402903,TLW2320840,TLW2470648,TLW2124384,TLW2622340,TLW1919244,TLW1523371,TLW1979414,TLW2108659,TLW1753760,TLW1683216,TLW2107666,TLW1815587,TLW1618373,TLW1680744,TLW1614967,TLW2380457,TLW1801199,TLW2199013,TLW2363478,TLW2203383,TLW2562625,TLW1828859,TLW1972379,TLW1690948,TLW2450573,TLW2347973,TLW2027005,TLW2100816,TLW2411620,TLW2004683,TLW1683990,TLW2388040,TLW1515189,TLW1924274,TLW2365545,TLW2486647,TLW1869352,TLW2282352,1378491,TLW1973576,TLW1808744,TLW2092641,TLW1675096,TLW2291506,TLW2486906,1424488,TLW1979168,TLW2143944,TLW2053958,TLW2630182,TLW2008105,TLW2454518,TLW2134736,1340341,TLW1818003,TLW1981238,TLW2638161,TLW2009941,TLW2539268,TLW2083293,TLW1805870,TLW2057095,TLW2357868,TLW2065715,TLW1903027,TLW2477035,TLW2370611,TLW2261686,1335341,TLW1686918,TLW2281213,TLW1630475,TLW2186486,TLW1725646,TLW2123599,1469041,TLW2239463,TLW2034847,1506391,TLW1818015,TLW1537097,TLW2333336,TLW2074401,1319262,TLW2365668,TLW2073541,TLW1975204,TLW2020688,TLW2303581,TLW1714526,TLW2011786,TLW1610026,TLW1866389,TLW2237038,TLW2235040,TLW2149227,TLW2006298,TLW1603676,TLW2364277,TLW2637848,TLW1993366,TLW2134692,TLW2621597,TLW2548762,TLW2324493,TLW2328137,TLW2445135,TLW2344233,TLW1992244,1306219,TLW1736968,TLW2543480,1452240,TLW2537238,TLW1690284,TLW1844943,1391704,TLW2111826,TLW2154919,TLW1897235,1425110,1415191,TLW2623504,TLW2164047,TLW2343854,TLW1737761,TLW1648742,TLW2540904,TLW1658419,TLW2154489,TLW1786578,TLW2468509,TLW1683153,TLW1759345,TLW2457899,1389076,TLW2449671,TLW2035698,TLW2270850,TLW2329321,TLW2361102,TLW2247133,TLW1721065,TLW2343484,TLW2348228,TLW2153403,TLW1860316,TLW2054800,TLW2549080,TLW2414732,TLW2169633,TLW2365223,TLW1952219,TLW1925447,TLW2625448,TLW1862999,TLW1851841,TLW1575313,TLW1609082,TLW1830424,1487849,TLW1617394,TLW1989146,TLW1895217,TLW1799821,TLW2188462,TLW1583981,TLW2505910,TLW2221544,TLW2050631,1319268,TLW2538753,TLW2356920,TLW1778014,TLW2383302,TLW2243353,TLW2202977,TLW1784743,TLW2210660,TLW2306153,TLW2406387,TLW2631808,TLW2489379,TLW2358188,1420394,TLW1657485,TLW2515081,TLW2229327,TLW1970998,TLW2507718,TLW2303422,1319256,TLW1569003,TLW1926302,TLW2408341,TLW1787518,TLW2131536,TLW2226519,TLW1541921,TLW2244154,TLW2104470,TLW2213301,TLW2295776,TLW2185381,TLW1866377,TLW1910584,1486527,TLW2342567,1513786,TLW2050399,TLW1750317,1493573,TLW1739638,TLW1577159,TLW2544270,TLW1853839,TLW2181069,TLW1905836,TLW2102073,TLW2054258,TLW2484775,1331257,TLW1804990,TLW1714955,TLW2306587,TLW1724782,TLW1517045,TLW2538157,TLW2143548,TLW1815092,TLW1912539,TLW2102224,TLW2316421,TLW1709467,TLW2447728,TLW1864359,TLW1700059,TLW1725538,TLW2360398,TLW1907548,TLW1670311,1399455,TLW2102615,TLW2628955,TLW2316557,TLW2055748,TLW2452231,TLW1526480,TLW1604159,TLW2319928,TLW2057011,TLW1691184,TLW2407487,TLW2047257,1498130,TLW1855998,1419178,TLW2146241,TLW2429000,TLW1956837,TLW1814695,TLW2076919,TLW2398397,TLW2486009,TLW2316956,TLW2557270,TLW2047630,TLW1657369,TLW1685095,TLW1736768,TLW2174579,TLW1831476,TLW1811970,TLW1573725,TLW1772616,TLW1568288,TLW2193202,TLW2234233,TLW2055255,TLW1627297,TLW1829540,TLW2426395,TLW2434591,TLW1763897,TLW2342202,TLW2221822,1385993,TLW1842384,TLW1614412,TLW2182165,TLW2192553,TLW1955888,TLW1744722,1430695,TLW1519074,TLW1761866,TLW1913512,TLW2470630,TLW1664947,TLW2281656,TLW2262064,TLW2194194,TLW1692682,TLW2294200,TLW2283210,TLW1998110,TLW1768476,TLW1862954,TLW2136692,TLW2333751,TLW1741103,TLW1965422,TLW1632405,TLW1602933,TLW2341209,TLW1830709,TLW2065461,TLW2421822,TLW2147277,TLW1733480,TLW1821169,TLW2222079,TLW2281015,TLW2455819,TLW1682266,TLW2217011,TLW2480819,TLW2004596,TLW1677764,TLW2115138,TLW1968294,TLW2439515,TLW1810060,TLW2196841,TLW2081836,TLW2457095,TLW2631364,1496444,TLW2169855,TLW1705358,TLW2351285,TLW2106636,TLW1758803,TLW1846836,TLW2464075,TLW2055601,TLW2325262,TLW2192888,TLW2365232,TLW1693345,TLW1767215,TLW2124547,TLW2018713,1365009,TLW2304447,TLW2176772,TLW2346806,TLW1633339,TLW2012395,TLW1515894,TLW1980919,TLW1645799,1334817,TLW2559985,TLW2341905,TLW2633040,TLW1633853,TLW1792310,TLW1694783,TLW2293105,TLW2030144,TLW1961668,TLW1830812,TLW1665506,TLW1520263,TLW1571161,1341924,TLW2084489,TLW1622891,TLW2459506,TLW1900534,TLW1904900,TLW1776320,TLW2064408,TLW2389440,TLW1728630,TLW1618283,TLW2372216,TLW2455384,TLW2371692,TLW2558483,TLW2146298,TLW1905788,TLW2414024,TLW1601855,TLW2010911,TLW2162653,TLW1688899,TLW2222229,TLW2110180,TLW1822946,TLW2005853,TLW2584743,TLW2392374,TLW2341555,TLW2122044,TLW1979524,TLW1995357,TLW2399128,TLW1860688,TLW1640246,TLW1742635,TLW1804034,TLW2243488,TLW2633845,TLW1748852,TLW2191140,1463663,TLW2035384,TLW2290076,TLW1709276,TLW2526052,TLW2084664,TLW2198318,TLW2530140,TLW2071921,TLW1719823,TLW1713601,TLW1775506,TLW2314682,TLW2498917,TLW2436725,TLW2164422,TLW2135479,TLW2538521,TLW1707722,TLW2091206,TLW2106883,1450382,TLW2543648,TLW2498537,TLW2343282,TLW2239328,TLW2351884,TLW1836941,TLW2358073,TLW2618336,TLW1593846,TLW2336584,TLW2301069,TLW2365735,TLW2558031,TLW2406429,TLW2273978,TLW2228260,TLW1654127,TLW2041625,TLW2045258,TLW2055072,TLW2647355,TLW1830389,1382498,TLW2338668,TLW2232835,TLW2391201,TLW1847537,TLW2210041,TLW1724661,TLW1960391,TLW1843238,TLW2626853,TLW2587111,TLW2492790,TLW2004181,1469766,TLW2428583,TLW2491023,TLW1703427,TLW2542820,TLW2059452,TLW2296094,TLW2425087,TLW1814255,TLW1849959,TLW2642191,TLW2198446,1456610,TLW2423451,TLW1967500,TLW2000297,TLW1581781,TLW2240628,TLW1610107,TLW2252401,TLW2212637,TLW1601608,TLW2475255,TLW1607973,TLW2334557,1390964,TLW2628505,TLW1806573,TLW2634431,TLW2374398,TLW1715841,TLW1742811,TLW2551830,TLW1613882,TLW1586823,TLW1699933,TLW2198792,TLW2644776,TLW2447706,TLW2451476,TLW1824466,TLW2179413,TLW2593732,TLW2338101,TLW2408260,TLW1787128,TLW1649737,TLW1630931,TLW1879227,TLW1980672,TLW2366250,TLW2085205,TLW2335195,TLW1804227,TLW1582049,TLW2195634,TLW2306700,TLW2185024,TLW1767266,TLW2302524,TLW2076027,TLW2077638,TLW1890877,TLW2225297,TLW1544315,TLW2110453,1377758,TLW2048216,TLW2636487,TLW2266320,TLW2166702,TLW1953198,TLW1806707,TLW2345975,TLW1980135,TLW2089646,TLW1538687,TLW1834163,TLW2626432,TLW2473166,TLW1779960,TLW1715433,TLW2182269,TLW2541753,TLW2195777,TLW1794848,TLW1653324,TLW2455130,TLW2611666,TLW2245068,TLW1962392,1459713,TLW2279269,TLW1732003,TLW1918602,TLW2119501,1503821,TLW1592512,TLW2294107,TLW2268007,TLW2381214,TLW2302907,TLW2194424,TLW2298486,TLW2352940,TLW2585307,TLW2268406,TLW2256606,TLW1669840,TLW2160088,TLW2147389,TLW2187254,TLW1742457,TLW2103771,TLW2295592,TLW2397550,TLW2254772,TLW2134847,TLW2251829,TLW1781664,TLW2081518,TLW1662010,TLW2389997,TLW2357093,TLW2176665,TLW1771773,TLW1828355,TLW1758151,TLW2382641,TLW1559921,TLW2328352,TLW1791721,TLW2553351,TLW1579614,TLW1537799,TLW2311542,TLW1967158,TLW1848301,TLW1587512,TLW1771169,TLW1726796,TLW1995555,TLW1562741,TLW2424043,TLW1715199,TLW2504558,TLW2255128,TLW2463804,TLW2179869,TLW2271913,TLW1766058,TLW2123238,TLW1535386,TLW1833082,TLW1658339,TLW1718056,TLW1719345,TLW1767720,TLW2254426,TLW1565549,TLW1585159,TLW2008825,TLW1835306,TLW2277036,TLW2068782,TLW1798746,TLW1888679,TLW2356489,1497219,TLW1766474,TLW1652667,TLW2075582,TLW2309522,TLW2363227,TLW2097618,TLW1854411,TLW2640103,TLW2641794,TLW1775123,TLW1975681,TLW2011705,TLW1733769,TLW2123164,TLW2133432,TLW2164130,TLW2251407,TLW2379079,TLW1631410,TLW1668964,TLW1789134,TLW2240087,1367508,TLW1857057,1416685,TLW1987471,TLW1899779,TLW2325370,TLW1803759,TLW2154984,1447883,TLW1957700,1491633,TLW2151011,TLW1570258,TLW2470112,TLW2416747,TLW2136763,TLW1693539,TLW1634243,TLW2323841,TLW2520068,TLW2354529,1491326,TLW1687008,TLW1872759,TLW2624663,TLW2178646,TLW2100973,1333477,TLW2633340,TLW1733836,TLW2425867,TLW1869556,TLW2549426,TLW1783728,TLW2228632,TLW2515817,TLW1629513,TLW1521697,TLW2499507,1507225,TLW2015450,TLW2424721,TLW1773895,TLW1677913,TLW2432217,1453044,TLW1693279,TLW2357911,TLW2014173,TLW2266071,TLW1647432,TLW2070246,TLW1722227,TLW2362006,TLW2438653,TLW2043441,TLW2238661,TLW2494432,TLW2109447,TLW2626725,TLW2168102,1331032,TLW1692265,TLW1805700,TLW1713926,TLW1679151,TLW1779656,TLW1776022,TLW1589385,TLW1851980,TLW2222047,TLW2328559,TLW2058088,TLW2173899,TLW2509557,TLW2261362,TLW1991054,TLW2197490,TLW2321226,TLW1729263,TLW2137811,TLW2388576,TLW2365908,TLW2168662,TLW1773043,TLW2453497,TLW1592486,TLW2253533,TLW1618273,TLW2040611,TLW1722108,TLW1918652,TLW2240974,1344701,TLW2071520,TLW2366305,TLW1951025,TLW1823441,TLW2246502,TLW2494990,TLW2067048,1334392,TLW1554358,TLW2206567,TLW1972300,TLW2327828,TLW2090781,TLW1997529,TLW2134955,TLW2148777,TLW1579522,TLW2216144,TLW2546935,1319250,TLW1703960,TLW2477504,TLW1992890,TLW2418990,TLW2039338,TLW2403789,TLW2044797,TLW2552491,TLW2286258,TLW2337175,TLW1982492,TLW2239136,1427825,TLW1655386,TLW1982103,TLW2487947,TLW2008132,TLW2227242,TLW1820275,TLW1755604,TLW2324266,TLW2014760,TLW2129339,1492795,TLW1838698,TLW2542473,TLW1531307,TLW2024580,TLW1665269,TLW2427864,TLW2439702,TLW2380444,TLW2224732,TLW1706720,TLW2403208,TLW1831352,TLW1632273,TLW2037113,TLW2090465,TLW2077180,TLW2600255,TLW2137270,1356289,1376951,1382426,TLW2204152,TLW1675822,TLW1746609,TLW1646763,TLW2178389,TLW2333075,TLW1823898,TLW2515380,TLW1561282,TLW2452853,TLW2199246,TLW2355907,TLW2179999,TLW1912476,TLW1841688,TLW1895501,TLW2290633,TLW1834923,TLW2551714,1365065,TLW2221249,TLW1615186,TLW2404094,TLW1820516,TLW2189163,TLW2434484,TLW2079770,TLW1728355,TLW1986584,TLW2499196,TLW1791254,TLW2355305,TLW2526561,TLW1825155,TLW2173552,TLW2120934,TLW1574412,TLW2338482,TLW2139170,TLW2007232,TLW2233988,TLW2538762,TLW2049129,TLW2383489,TLW1603842,TLW2406438,TLW1900449,TLW2193481,TLW2287581,TLW1618768,TLW2338093,1347601,TLW2400613,TLW1810792,TLW2308634,TLW2007314,TLW2315306,TLW2314865,TLW2181523,TLW1725965,TLW2120296,TLW2412819,TLW2501030,TLW2443153,TLW1680514,TLW2440181,TLW2386622,TLW2270048,TLW2279812,TLW2023959,TLW1858937,TLW2581559,1487906,TLW2190334,TLW2114687,TLW2239816,TLW2369874,1456931,TLW2349915,TLW2175877,TLW2514485,TLW2282914,TLW2023342,TLW2494886,TLW2187881,TLW2457553,TLW2478985,TLW2107848,TLW1572809,TLW2071766,TLW2340173,TLW1821462,TLW2215306,TLW1722972,TLW2138953,TLW1559171,TLW2079554,TLW2473157,TLW1724673,1454353,TLW1592183,TLW2028053,TLW1678484,TLW2570153,TLW2007792,TLW2442858,TLW2130496,TLW1972163,TLW2525091,TLW2033337,TLW2129842,TLW2126681,TLW1978862,TLW2397707,TLW1905491,TLW2389490,TLW1749240,TLW1757214,TLW2560147,TLW1822471,TLW2279178,TLW2031740,TLW2050480,TLW1961727,TLW2065606,1393343,TLW2282925,TLW1875137,TLW1627582,TLW2325660,TLW2268762,TLW2455911,TLW2259124,TLW2017183,TLW2330393,TLW1572180,TLW2535881,1487359,TLW2466010,TLW2139839,TLW2526013,TLW2307613,TLW2085894,TLW2262783,TLW1840611,TLW2527897,TLW1947800,TLW1623793,TLW2293788,TLW1591402,TLW2377576,TLW2308340,TLW2441534,TLW1824087,TLW2234044,TLW2194440,TLW2426974,TLW2442023,TLW1969781,TLW2434331,TLW2042990,TLW1674732,TLW1979115,TLW2335260,TLW2545138,TLW2540639,TLW1601184,TLW2326554,TLW2369964,TLW2446428,TLW2277985,TLW2127665,TLW2362707,TLW2540694,TLW2505671,TLW2558976,TLW1560946,TLW1914673,TLW2006915,TLW2187265,TLW2320293,TLW2275123,TLW1692752,TLW2348606,TLW2314111,TLW2394966,TLW2423314'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(non_exact_ld_matches_df) \n",
    "q_sim_df = tf_idf_similarity_df(df, col='clean_description', vect_max_feats=1000, n_splits=1)\n",
    "similarity = 0.75\n",
    "get_similar_wonums(q_sim_df, df, index_key=0, similarity=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Below we'll output an example cluster of workorders matched based on their description*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which description best matches what you are looking for?\n",
      "\n",
      "0                          Re-Instate Brake Smart Valve\n",
      "1                   20/03 411 Brake Release Key Missing\n",
      "2                          Re-Instate Brake Smart Valve\n",
      "4     411 - EP2002 Smart Valve Failing brake test to...\n",
      "5     Bogie 2 brake reservoir pressure too low - 406...\n",
      "7           Brake blocks to be replaced. X4 (See long).\n",
      "8            15/04 - AWS Unsolicited brake demand - 401\n",
      "9           407 - wheel 4 parking brake cylinder damage\n",
      "10               404 Brake resister trunking broken off\n",
      "12                         Re-Instate Brake Smart Valve\n",
      "13                         Re-Instate Brake Smart Valve\n",
      "14    21/03  -  Blank HMI, DMI and Emergency Brake a...\n",
      "15    Coach 410 Displaying emergency brake applied o...\n",
      "16            Brake components  - Brake block - Replace\n",
      "17                         Re-Instate Brake Smart Valve\n",
      "20                         carry out brake test RRBX006\n",
      "21                         Re-Instate Brake Smart Valve\n",
      "23                        03/09 Auto brake test failure\n",
      "24                         Re-Instate Brake Smart Valve\n",
      "26                         Re-Instate Brake Smart Valve\n",
      "27                         Re-Instate Brake Smart Valve\n",
      "28    27/07 402 BCU 1 comms failure - minor loss of ...\n",
      "29    Power brake controller defective in active cab...\n",
      "30    Coach 412, Emergency brakes apply once an EVC/...\n",
      "31          ++RB2 switch off parking brake valve failed\n",
      "32                         Re-Instate Brake Smart Valve\n",
      "33    410 minor loss of pneumatic brake force - LOM ...\n",
      "34                         Re-Instate Brake Smart Valve\n",
      "35                         Re-Instate Brake Smart Valve\n",
      "36                         Re-Instate Brake Smart Valve\n",
      "37              Brake components  - Brake pad - Inspect\n",
      "38                         Re-Instate Brake Smart Valve\n",
      "40                         Re-Instate Brake Smart Valve\n",
      "41                         Re-Instate Brake Smart Valve\n",
      "42        10/06 Minor loss of pneumatic brake force 412\n",
      "43    S3 South – RRBP103 Brake components  - Brake b...\n",
      "44                412 Brakes Applied Due to DMI Failure\n",
      "45                         Re-Instate Brake Smart Valve\n",
      "46                         Re-Instate Brake Smart Valve\n",
      "47                         Re-Instate Brake Smart Valve\n",
      "48                         Re-Instate Brake Smart Valve\n",
      "49        loss of Pneumatic  brake force(see long disc)\n",
      "50    402 BCU failing Brake test - Gateway Medium Fa...\n",
      "51                         Re-Instate Brake Smart Valve\n",
      "52      27/07 - Minor Loss Brake Force After Changeover\n",
      "54                 Multiple parking brake hoses rubbing\n",
      "55                         Re-Instate Brake Smart Valve\n",
      "57              5 x under size brake blocks ( see long)\n",
      "58                         Re-Instate Brake Smart Valve\n",
      "59                           412 ETCS Brake Application\n",
      "Name: description, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wonum</th>\n",
       "      <th>description</th>\n",
       "      <th>ldtext</th>\n",
       "      <th>mats_assigned</th>\n",
       "      <th>wopriority</th>\n",
       "      <th>actstart</th>\n",
       "      <th>clean_ldtext</th>\n",
       "      <th>clean_description</th>\n",
       "      <th>clean_ldtext_size</th>\n",
       "      <th>clean_description_size</th>\n",
       "      <th>clean_description_clean_ldtext</th>\n",
       "      <th>all_relevant_mats</th>\n",
       "      <th>count</th>\n",
       "      <th>group_id</th>\n",
       "      <th>similar_clean_description_ldtext</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>wonum_fuzz_matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1427950</td>\n",
       "      <td>Multiple parking brake hoses rubbing</td>\n",
       "      <td>locations are as follows: 411 bogie 1 411 bogi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2019-01-28 03:38:25</td>\n",
       "      <td>['location', 'follows', 'bogie', 'bogie', 'bog...</td>\n",
       "      <td>['multiple', 'parking', 'brake', 'hose', 'rubb...</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>['multiple', 'parking', 'brake', 'hose', 'rubb...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1427950,TLW2261346,TLW1555509,TLW2071536,12926...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>TLW1535017</td>\n",
       "      <td>Multiple parking brake hoses rubbing</td>\n",
       "      <td>Parking brake hoses rubbing at the following l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2019-07-18 17:10:00</td>\n",
       "      <td>['parking', 'brake', 'hose', 'rubbing', 'follo...</td>\n",
       "      <td>['multiple', 'parking', 'brake', 'hose', 'rubb...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>['multiple', 'parking', 'brake', 'hose', 'rubb...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1427950,TLW2261346,TLW1555509,TLW2071536,12926...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>TLW2071536</td>\n",
       "      <td>Multiple parking brake hoses rubbing (see long)</td>\n",
       "      <td>402 axle 4 - rubbed through to re-enforcement ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2022-07-22 19:10:25</td>\n",
       "      <td>['axle', 'rubbed', 'reenforcement', 'axle']</td>\n",
       "      <td>['multiple', 'parking', 'brake', 'hose', 'rubb...</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>['multiple', 'parking', 'brake', 'hose', 'rubb...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1427950,1408635,TLW1572826,TLW2071536,TLW20533...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           wonum                                      description  \\\n",
       "54       1427950             Multiple parking brake hoses rubbing   \n",
       "1982  TLW1535017             Multiple parking brake hoses rubbing   \n",
       "400   TLW2071536  Multiple parking brake hoses rubbing (see long)   \n",
       "\n",
       "                                                 ldtext mats_assigned  \\\n",
       "54    locations are as follows: 411 bogie 1 411 bogi...           NaN   \n",
       "1982  Parking brake hoses rubbing at the following l...           NaN   \n",
       "400   402 axle 4 - rubbed through to re-enforcement ...           NaN   \n",
       "\n",
       "      wopriority            actstart  \\\n",
       "54           9.0 2019-01-28 03:38:25   \n",
       "1982         3.0 2019-07-18 17:10:00   \n",
       "400          9.0 2022-07-22 19:10:25   \n",
       "\n",
       "                                           clean_ldtext  \\\n",
       "54    ['location', 'follows', 'bogie', 'bogie', 'bog...   \n",
       "1982  ['parking', 'brake', 'hose', 'rubbing', 'follo...   \n",
       "400         ['axle', 'rubbed', 'reenforcement', 'axle']   \n",
       "\n",
       "                                      clean_description  clean_ldtext_size  \\\n",
       "54    ['multiple', 'parking', 'brake', 'hose', 'rubb...                  7   \n",
       "1982  ['multiple', 'parking', 'brake', 'hose', 'rubb...                  6   \n",
       "400   ['multiple', 'parking', 'brake', 'hose', 'rubb...                  4   \n",
       "\n",
       "      clean_description_size  \\\n",
       "54                         5   \n",
       "1982                       5   \n",
       "400                        7   \n",
       "\n",
       "                         clean_description_clean_ldtext all_relevant_mats  \\\n",
       "54    ['multiple', 'parking', 'brake', 'hose', 'rubb...                []   \n",
       "1982  ['multiple', 'parking', 'brake', 'hose', 'rubb...                []   \n",
       "400   ['multiple', 'parking', 'brake', 'hose', 'rubb...                []   \n",
       "\n",
       "      count  group_id similar_clean_description_ldtext  exact_match  \\\n",
       "54      NaN       NaN                              NaN            0   \n",
       "1982    NaN       NaN                              NaN            0   \n",
       "400     NaN       NaN                              NaN            0   \n",
       "\n",
       "                                     wonum_fuzz_matches  \n",
       "54    1427950,TLW2261346,TLW1555509,TLW2071536,12926...  \n",
       "1982  1427950,TLW2261346,TLW1555509,TLW2071536,12926...  \n",
       "400   1427950,1408635,TLW1572826,TLW2071536,TLW20533...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cluster_info(q_sim_df,df,'brake',similarity=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tf_idf_wonum_match'] = None\n",
    "df['tf_idf_wonum_match'] = df.apply(lambda row: get_similar_wonums(q_sim_df,df, index_key=row.name, similarity=0.75), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2vec(test_df: pd.DataFrame, text_col: str, vs: int, e: int, win: int, sim_thr: float):\n",
    "\n",
    "    '''\n",
    "    Input:  \n",
    "    text_col: The column of the df which contains the tokenised clean text.\n",
    "              This column should have the form '['side', 'b', 'bogie',...]' or '[]'\n",
    "    vs: Vector size parameter of Doc2Vec\n",
    "    e: Epochs parameter of Doc2Vec\n",
    "    win: Window parameter of Doc2Vec\n",
    "\n",
    "    Output:\n",
    "    model: A Doc2Vec model trained on corpus provided with params provided and min_count=2\n",
    "    \n",
    "    '''\n",
    "    corpus = test_df[text_col]\n",
    "    tagged_data = [TaggedDocument(words=ast.literal_eval(doc), tags=[str(i)]) for i, doc in enumerate(corpus)]\n",
    "    print(f'First couple of Tagged data: {tagged_data[0:2]}')\n",
    "    print(f'Length of tagged data is {len(tagged_data)}')\n",
    "\n",
    "    # Initialize Doc2Vec model\n",
    "    model = Doc2Vec(vector_size=vs, min_count=2, epochs=e, window=win)\n",
    "\n",
    "    # Build vocabulary\n",
    "    model.build_vocab(tagged_data)\n",
    "\n",
    "    # Train the model\n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.epochs)\n",
    "    print(f'Model with vec_size={model.vector_size}, window={model.window} and epochs={model.epochs} has been succefully trained based on {text_col}')\n",
    "    # Get the document embedding vectors\n",
    "    #document_vectors = [model.infer_vector(ast.literal_eval(doc)) for doc in corpus]\n",
    "\n",
    "\n",
    "    test_df[f\"similar_{text_col}_wonums\"] = \"\"\n",
    "    test_df[f\"similar_{text_col}_index\"] = \"\"\n",
    "\n",
    "    # Initialize an empty list to store wonum values\n",
    "    wonum_list = []\n",
    "    similar_wonums = []\n",
    "    index_list = []\n",
    "    similar_index = []\n",
    "\n",
    "\n",
    "    # Loop through each document in test_df\n",
    "    for doc_id in range(len(test_df)):\n",
    "        inferred_vector = model.infer_vector(tagged_data[doc_id].words)\n",
    "        sims = model.dv.most_similar([inferred_vector], topn= int(len(tagged_data)/100))\n",
    "\n",
    "        # Use boolean indexing to filter similar wonum values\n",
    "        similar_wonums = [test_df.iloc[int(sim[0])][\"wonum\"] for sim in sims if (sim[1] > sim_thr)]  #and (int(sims[0][0]) !=  doc_id)\n",
    "        similar_index = [ int(sim[0]) for sim in sims if (sim[1] > sim_thr)]  #and (int(sims[0][0]) !=  doc_id)\n",
    "           \n",
    "        # Append the list of similar wonum values to wonum_list\n",
    "        wonum_list.append(similar_wonums if len(similar_wonums) != 1 else '')\n",
    "        index_list.append(similar_index if len(similar_index) != 1 else '')\n",
    "\n",
    "    # Assign the array to the new column in test_df\n",
    "    test_df[f\"doc2vec_similar_{text_col}_wonums\"] = np.array([\",\".join(map(str, row)) for row in wonum_list ])\n",
    "    test_df[f\"doc2vec_similar_{text_col}_index\"] = np.array([\",\".join(map(str, row)) for row in index_list ])\n",
    "    \n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = doc2vec(df, text_col='clean_description', vs=125, win=4, e=50, sim_thr=0.8)\n",
    "test_df[[\"description\", \"ldtext\", \"doc2vec_similar_clean_description_wonums\", \"doc2vec_similar_clean_description_index\"]].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Test for nearest matches:\n",
    "\n",
    "for doc_id in range(0, 6):\n",
    "\n",
    "    inferred_vector = model.infer_vector(tagged_data[doc_id].words)\n",
    "    sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "\n",
    "    print('\\nDocument ({}): «{}»'.format(\n",
    "        doc_id, ' '.join(tagged_data[doc_id].words)))\n",
    "    for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('THIRD-MOST', 3), ('FOURTH-MOST', 4), ('FIFTH-MOST', 5), ('LEAST', len(sims) - 1)]:\n",
    "        # if (sims[index][1] > 0.85):\n",
    "        print(u'%s %s: «%s»' % (label, sims[index], ' '.join(\n",
    "            tagged_data[int(sims[index][0])].words)))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
